{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "543b7050",
   "metadata": {},
   "source": [
    "# Income Classification using Logistic Regression\n",
    "\n",
    "In this project, I will use a dataset containing census information from the 1994 Census to create a logistic regression model, that predicts whether or not a person makes more than $50,000 a year.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "Data set is available at the [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/20/census+income).\n",
    "\n",
    "### Features\n",
    "\n",
    "Input and Output `features`:\n",
    "* age: continuous\n",
    "* workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "* education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool\n",
    "* race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\n",
    "* sex: Female, Male\n",
    "* capital-gain: continuous\n",
    "* capital-loss: continuous\n",
    "* hours-per-week: continuous\n",
    "* native country: discrete\n",
    "* income: discrete, >50K, <=50K\n",
    "\n",
    "------\n",
    "\n",
    "### EDA and Logistic Regression Assumptions\n",
    "1. The dataset has been saved as a dataframe named `df`. The outcome variable here is `income`. Check if the dataset is `imbalanced`.\n",
    "2. Notice we have created a variable named `feature_cols`. This contains a list of the variables we will use as our predictor variables.\n",
    "    `Transform` the dataset of predictor variables to dummy variables and save this in a new DataFrame called `X`.\n",
    "3. Using `X`, create a `heatmap` of the correlation values.\n",
    "4. Determine if `scaling` is needed for `X` prior to modeling. Then create the `y` output variable which is binary, `0` when income is less than $50K, `1` when greater than $50K.\n",
    "\n",
    "### Logistic Regression Models and Evaluation\n",
    "5. Split the data into a training and testing set. Set the `random_state` to 1 and `test_size` to `.2`.\n",
    "6. Print the model parameters (`intercept` and `coefficients`).\n",
    "7. Evaluate the predictions of the model on the `test set`. Print the `confusion matrix` and `accuracy score`.\n",
    "8. Create a new DataFrame of the model coefficients and variable names. Sort values based on coefficient and exclude any that are equal to zero. Print the values of the DataFrame.\n",
    "9. Create a `barplot` of the coefficients sorted in ascending order.\n",
    "10. Plot the `ROC curve` and print the `AUC value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e056342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              40           Cuba  <=50K  \n",
      "Model Parameters, Intercept:\n",
      "Model Parameters, Coeff:\n",
      "Confusion Matrix on test set:\n",
      "Accuracy Score on test set:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "col_names = ['age', 'workclass', 'fnlwgt','education', 'education-num', \n",
    "'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "'capital-gain','capital-loss', 'hours-per-week','native-country', 'income']\n",
    "df = pd.read_csv('adult.data',header = None, names = col_names)\n",
    "\n",
    "#Clean columns by stripping extra whitespace for columns of type \"object\"\n",
    "for c in df.select_dtypes(include=['object']).columns:\n",
    "    df[c] = df[c].str.strip()\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62601a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Check Class Imbalance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c11aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Create feature dataframe X with feature columns and dummy variables for categorical features\n",
    "feature_cols = ['age','capital-gain', 'capital-loss', 'hours-per-week', 'sex','race', 'hours-per-week', 'education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9265a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Create a heatmap of X data to see feature correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a1b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Create output variable y which is binary, 0 when income is less than 50k, 1 when it is greater than 50k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6574a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5a. Split data into a train and test set\n",
    "\n",
    "\n",
    "#5b. Fit LR model with sklearn on train set, and predicting on the test set\n",
    "log_reg = LogisticRegression(C=0.05, penalty='l1', solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff01d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Print model parameters (intercept and coefficients)\n",
    "print('Model Parameters, Intercept:')\n",
    "\n",
    "print('Model Parameters, Coeff:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Evaluate the predictions of the model on the test set. Print the confusion matrix and accuracy score.\n",
    "print('Confusion Matrix on test set:')\n",
    "print('Accuracy Score on test set:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18637d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8.Create new DataFrame of the model coefficients and variable names; sort values based on coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ff2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#9. barplot of the coefficients sorted in ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6bb080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Plot the ROC curve and print the AUC value.\n",
    "#y_pred_prob = log_reg.predict_proba(x_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
